{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7s2q1YPF-m0",
        "outputId": "b2b7e9c8-ce96-4c10-b27d-b31ce1988462"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'im-tutorials'...\n",
            "remote: Enumerating objects: 230, done.\u001b[K\n",
            "remote: Counting objects: 100% (230/230), done.\u001b[K\n",
            "remote: Compressing objects: 100% (158/158), done.\u001b[K\n",
            "remote: Total 230 (delta 95), reused 184 (delta 55), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (230/230), 10.54 MiB | 16.78 MiB/s, done.\n",
            "Resolving deltas: 100% (95/95), done.\n"
          ]
        }
      ],
      "source": [
        "# Before we begin, run this cell if you are using Colab\n",
        "!git clone -b 3-ysi-tutorial https://github.com/nestauk/im-tutorials.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MeEm67NF-nL"
      },
      "source": [
        "# Web Scraping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHNVtLgTF-nO"
      },
      "outputs": [],
      "source": [
        "from IPython.core.display import display, HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "VhdnrySnF-nO",
        "outputId": "f4acf6d7-75f6-4798-b527-72f285fa36ef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<!DOCTYPE html>\n",
              "<html lang=\"en\" dir=\"ltr\">\n",
              "<head>\n",
              "  <title>Intro to HTML</title>\n",
              "</head>\n",
              "\n",
              "<body>\n",
              "  <h1>Heading h1</h1>\n",
              "  <h2>Heading h2</h2>\n",
              "  <h3>Heading h3</h3>\n",
              "  <h4>Heading h4</h4>\n",
              "\n",
              "  <p>\n",
              "    That's a text paragraph. You can also <b>bold</b>, <mark>mark</mark>, <ins>underline</ins>, <del>strikethrough</del> and <i>emphasize</i> words.\n",
              "    You can also add links - here's one to <a href=\"https://en.wikipedia.org/wiki/Main_Page\">Wikipedia</a>.\n",
              "  </p>\n",
              "\n",
              "  <p>\n",
              "    This <br> is a paragraph <br> with <br> line breaks\n",
              "  </p>\n",
              "\n",
              "  <p style=\"color:red\">\n",
              "    Add colour to your paragraphs.\n",
              "  </p>\n",
              "\n",
              "  <p>Unordered list:</p>\n",
              "  <ul>\n",
              "    <li>Python</li>\n",
              "    <li>R</li>\n",
              "    <li>Julia</li>\n",
              "  </ul>\n",
              "\n",
              "  <p>Ordered list:</p>\n",
              "  <ol>\n",
              "    <li>Data collection</li>\n",
              "    <li>Exploratory data analysis</li>\n",
              "    <li>Data analysis</li>\n",
              "    <li>Policy recommendations</li>\n",
              "  </ol>\n",
              "  <hr>\n",
              "\n",
              "  <!-- This is a comment -->\n",
              "\n",
              "</body>\n",
              "</html>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(HTML(\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\" dir=\"ltr\">\n",
        "<head>\n",
        "  <title>Intro to HTML</title>\n",
        "</head>\n",
        "\n",
        "<body>\n",
        "  <h1>Sample Website</h1>\n",
        "  <h2>Heading h2</h2>\n",
        "  <h3>Heading h3</h3>\n",
        "  <h4>Heading h4</h4>\n",
        "\n",
        "  <p>\n",
        "    That's a text paragraph. You can also <b>bold</b>, <mark>mark</mark>, <ins>underline</ins>, <del>strikethrough</del> and <i>emphasize</i> words.\n",
        "    You can also add links - here's one to <a href=\"https://en.wikipedia.org/wiki/Main_Page\">Wikipedia</a>.\n",
        "  </p>\n",
        "\n",
        "  <p>\n",
        "    This <br> is a paragraph <br> with <br> line breaks\n",
        "  </p>\n",
        "\n",
        "  <p style=\"color:red\">\n",
        "    Add colour to your paragraphs.\n",
        "  </p>\n",
        "\n",
        "  <p>Unordered list:</p>\n",
        "  <ul>\n",
        "    <li>Python</li>\n",
        "    <li>R</li>\n",
        "    <li>Julia</li>\n",
        "  </ul>\n",
        "\n",
        "  <p>Ordered list:</p>\n",
        "  <ol>\n",
        "    <li>Data collection</li>\n",
        "    <li>Exploratory data analysis</li>\n",
        "    <li>Data analysis</li>\n",
        "    <li>Policy recommendations</li>\n",
        "  </ol>\n",
        "  <hr>\n",
        "\n",
        "  <!-- This is a comment -->\n",
        "\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrPp8opCF-nT"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O79rtwX-F-nT",
        "outputId": "3fec67cb-c589-4362-e92a-282ececfc5c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<title>IMDb: Ratings, Reviews, and Where to Watch the Best Movies &amp; TV Shows</title>"
            ]
          },
          "execution_count": 5,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# IMDB's homepage\n",
        "imdb_url = 'https://www.imdb.com'\n",
        "\n",
        "# Use requests to retrieve data from a given URL\n",
        "imdb_response = requests.get(imdb_url)\n",
        "\n",
        "# Parse the whole HTML page using BeautifulSoup\n",
        "imdb_soup = BeautifulSoup(imdb_response.text, 'html.parser')\n",
        "\n",
        "# Title of the parsed page\n",
        "imdb_soup.title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eWKjb9S5F-nU",
        "outputId": "41e34ef0-d1f5-48f2-8aef-41b69e247fb0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'IMDb: Ratings, Reviews, and Where to Watch the Best Movies & TV Shows'"
            ]
          },
          "execution_count": 6,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We can also get it without the HTML tags\n",
        "imdb_soup.title.string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k2QYQoOF-nV"
      },
      "source": [
        "### Collect trailers' title and description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Q2VHVYbF-nW"
      },
      "outputs": [],
      "source": [
        "trailers = imdb_soup.find('div', {'class': 'ab_hero'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjiDZhqUF-nX"
      },
      "outputs": [],
      "source": [
        "# print(trailers.prettify())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45dTwxNMF-nX"
      },
      "source": [
        "We will use the `.find_all()` method to search the HTML tree for particular tags and get a `list` with all the relevant objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N87uPmUEF-nY"
      },
      "outputs": [],
      "source": [
        "for title, image in zip(trailers.find_all('div', {'class': 'onoverflow'}), trailers.find_all('img', {'class': 'pri_image'})):\n",
        "    print(f\"{title.text}: {image['title']}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbcSpZqgF-nY"
      },
      "source": [
        "### Collect side bar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkI1N_MbF-nZ"
      },
      "outputs": [],
      "source": [
        "for widget in imdb_soup.find_all('div', {'class': 'aux-content-widget-2'}):\n",
        "    # Check that the widget has a heading\n",
        "    if widget.h3:\n",
        "        # Print the widget's heading along with the movie titles.\n",
        "        print(widget.h3.string)\n",
        "        for title in widget.find_all('div', {'class': 'title'}):\n",
        "            print(title.text)\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygqryk8NF-nZ"
      },
      "source": [
        "### Collect articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIMnof3cF-nZ"
      },
      "outputs": [],
      "source": [
        "for article in imdb_soup.find_all('div', {'class': 'article'}):\n",
        "    if article.h3:\n",
        "        # Title of the article\n",
        "        print(article.h3.string)\n",
        "        # Text\n",
        "        print(article.p.text)\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHtfX9gSF-nZ"
      },
      "source": [
        "### Find links\n",
        "\n",
        "In many cases, it is useful to collect the links contained in a webpage (for example, you might want to scrape them too). Here is how you can do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-djM_w_bF-na"
      },
      "outputs": [],
      "source": [
        "# Find all links\n",
        "links = [link.get('href') for link in imdb_soup.find_all('a')]\n",
        "\n",
        "# Add homepage and keep the unique links\n",
        "fixed_links = set([''.join([imdb_url, link]) for link in links if link])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CdhxtctF-na"
      },
      "outputs": [],
      "source": [
        "# fixed_links"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGDOrb6mF-nb"
      },
      "source": [
        "## Data to analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7HUyejHF-nb"
      },
      "outputs": [],
      "source": [
        "# Box Office Mojo - UK Weekend box office\n",
        "boxofficemojo_url = 'https://www.boxofficemojo.com/intl/uk/?yr=2019&wk=33&currency=local'\n",
        "\n",
        "# Use requests to retrieve data from a given URL\n",
        "bom_response = requests.get(boxofficemojo_url)\n",
        "\n",
        "# Parse the whole HTML page using BeautifulSoup\n",
        "bom_soup = BeautifulSoup(bom_response.text, 'html.parser')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyYmVMzAF-nc"
      },
      "outputs": [],
      "source": [
        "# There are 7 tables in the Box Office Mojo page but we are interested in the one with the most data (table 5).\n",
        "print(f\"NUMBER OF TABLES IN THE PAGE: {len(bom_soup.find_all('table'))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m51BuFu8F-nc"
      },
      "outputs": [],
      "source": [
        "# Python starts counting from 0\n",
        "table = bom_soup.find_all('table')[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28yoeugLF-nd"
      },
      "outputs": [],
      "source": [
        "# table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9j9jaIZcF-nd"
      },
      "outputs": [],
      "source": [
        "# Using the .contents method\n",
        "table.find_all('tr')[2].contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hQGP8P4F-nf"
      },
      "outputs": [],
      "source": [
        "# Using .text method\n",
        "table.find_all('tr')[2].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrrPgTsIF-nf"
      },
      "outputs": [],
      "source": [
        "# Print text \"consumes\" the newline characters\n",
        "print(table.find_all('tr')[2].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzjA9DLVF-ng"
      },
      "outputs": [],
      "source": [
        "# Split string on newline characters\n",
        "table.find_all('tr')[2].text.split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NE8iVvgyF-nh"
      },
      "outputs": [],
      "source": [
        "# Loop through the cells of a row and print their data\n",
        "for data in table.find_all('tr')[2].find_all('td'):\n",
        "    print(data.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FurUTasF-nh"
      },
      "outputs": [],
      "source": [
        "# Table's column names\n",
        "for data in table.find_all('tr')[1].find_all('td'):\n",
        "    print(data.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wm-xJapF-ni"
      },
      "outputs": [],
      "source": [
        "# Loop over the table rows, collect the data and store them in a list.\n",
        "lst = []\n",
        "for row in table.find_all('tr')[1:-1]:\n",
        "    s = pd.Series([data.text for data in row.find_all('td')])\n",
        "    lst.append(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ImqRUxqF-nj"
      },
      "outputs": [],
      "source": [
        "# Concatenate the Pandas Series in a DataFrame\n",
        "data = pd.concat(lst, axis=1).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpJgZBtvF-nj"
      },
      "outputs": [],
      "source": [
        "# The first line contains the header - let's fix that!\n",
        "data.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iz7BYW8fF-nk"
      },
      "outputs": [],
      "source": [
        "# grab the first row for the header\n",
        "header = []\n",
        "for col in data.iloc[0, :-1]:\n",
        "    if '/' not in col:\n",
        "        header.append(col)\n",
        "    else:\n",
        "        header.extend(col.split('/'))\n",
        "\n",
        "data = data[1:] # take the data less the header row\n",
        "data.columns = header # set the header row as the df header"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1K1ILbDGF-nk"
      },
      "outputs": [],
      "source": [
        "# Replace the n/a string with a Null value.\n",
        "data.replace('n/a', np.nan, inplace=True)\n",
        "data.replace('-', np.nan, inplace=True)\n",
        "\n",
        "# Remove the £ symbol from the \"Gross\" column and transform strings to integers\n",
        "data['Weekend Gross'] = data['Weekend Gross'].apply(lambda x: int(x[1:].replace(',', '')))\n",
        "data['Gross-to-Date'] = data['Gross-to-Date'].apply(lambda x: int(x[1:].replace(',', '')))\n",
        "\n",
        "# Transform strings to integers\n",
        "data['Theaters'] = data['Theaters'].apply(lambda x: int(x) if isinstance(x, str) else x)\n",
        "data['Week'] = data['Week'].apply(lambda x: int(x) if isinstance(x, str) else x)\n",
        "\n",
        "# Create a new variable showing how much a movie grossed on average on weekly basis\n",
        "data['Week AVG'] = data['Gross-to-Date'].div(data['Week'])\n",
        "\n",
        "# Set the movie title as index\n",
        "data.set_index('Movie', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJFLrNNyF-nk"
      },
      "outputs": [],
      "source": [
        "data.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piU_lghPF-nl"
      },
      "outputs": [],
      "source": [
        "print(f'(MOVIES, COLUMNS) -> {data.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCQLA0VqF-nl"
      },
      "outputs": [],
      "source": [
        "print(f'% OF MISSING VALUES PER COLUMN\\n{(data.isnull().sum() / data.shape[0]) * 100}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaBUhCWHF-nl"
      },
      "outputs": [],
      "source": [
        "# Use the .value_counts() method to count the number of studios\n",
        "data.Studio.value_counts().plot(kind='bar', title='Studios with the most movies in the top 55')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Am7qaiDQF-nl"
      },
      "outputs": [],
      "source": [
        "# Use the .sort_values() method to sort the values of a column\n",
        "f, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,8))\n",
        "\n",
        "# ax1\n",
        "data['Week AVG'].sort_values(ascending=False)[:25].plot(kind='bar', title='Weekly Gross earnings', ax=ax1)\n",
        "# ax2\n",
        "data['Theaters'].sort_values(ascending=False)[:25].plot(kind='bar', title='Number of theaters showing a movie', ax=ax2)\n",
        "\n",
        "f.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip6xbD2oF-np"
      },
      "source": [
        "## USING SELENIUM IN COLAB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHzo8bu6F-np"
      },
      "outputs": [],
      "source": [
        "# # RUN THIS CELL WHEN USING THE NOTEBOOK LOCALLY - YOU SHOULD INSTALL SELENIUM FIRST\n",
        "# import selenium.webdriver\n",
        "# # Path to the Chrome driver for my Mac -- yours will differ\n",
        "# mac_path = '../../chromedriver'\n",
        "# driver = selenium.webdriver.Chrome(executable_path=mac_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yiwik1GDF-nq"
      },
      "outputs": [],
      "source": [
        "# # RUN THIS CELL WHEN USING THE NOTEBOOK ON COLAB - NO PREVIOUS INSTALLATION OF SELENIUM IS NEEDED\n",
        "# # install chromium, its driver, and selenium\n",
        "# !apt update\n",
        "# !apt install chromium-chromedriver\n",
        "# !pip install selenium\n",
        "# # set options to be headless\n",
        "# from selenium import webdriver\n",
        "# options = webdriver.ChromeOptions()\n",
        "# options.add_argument('--headless')\n",
        "# options.add_argument('--no-sandbox')\n",
        "# options.add_argument('--disable-dev-shm-usage')\n",
        "# # open it, go to a website, and get results\n",
        "# driver = webdriver.Chrome('chromedriver',options=options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Y39Ci_0F-nq"
      },
      "outputs": [],
      "source": [
        "def html2df(source, q):\n",
        "    \"\"\"A wrapper of the scraping pipeline we used before.\"\"\"\n",
        "    # Parse the HTML page\n",
        "    soup = BeautifulSoup(source, 'html.parser')\n",
        "\n",
        "    # Choose the relevant table\n",
        "    table = soup.find_all('table')[4]\n",
        "\n",
        "    # Parse and store the data of every table row\n",
        "    lst = []\n",
        "    for row in table.find_all('tr'):\n",
        "        s = pd.Series([data.text for data in row.find_all('td')])\n",
        "        lst.append(s)\n",
        "\n",
        "    # Concatenate the data in a Pandas DataFrame and place the first row of the DataFrame as header.\n",
        "    data = pd.concat(lst, axis=1).T\n",
        "\n",
        "    # Grab the first row for the header\n",
        "    new_header = data.iloc[0]\n",
        "\n",
        "    # Take the data less the header row\n",
        "    data = data[1:]\n",
        "\n",
        "    # Set the header row as the df header\n",
        "    data.columns = new_header\n",
        "    \n",
        "    # Add a new column tagging the page we scraped\n",
        "    data['page'] = q \n",
        "    \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMU8TNjbF-nr"
      },
      "outputs": [],
      "source": [
        "# URL to use in Selenium\n",
        "driver.get('https://www.boxofficemojo.com/intl/uk/yearly/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeU0jKhLF-nr"
      },
      "outputs": [],
      "source": [
        "lst = []\n",
        "lst.append(html2df(driver.page_source, '#1'))\n",
        "for i in ['#101', '#201', '#301', '#401']:\n",
        "    # Locate Hyperlinks by partial link text\n",
        "    elem = driver.find_element_by_partial_link_text(i)\n",
        "    # Click on the next page\n",
        "    elem.click()\n",
        "    # Store the Pandas DataFrame with the scraped content in a list\n",
        "    lst.append(html2df(driver.page_source, i))\n",
        "\n",
        "# Concatenate all Pandas DataFrames\n",
        "df = pd.concat(lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DISS7BbjF-nr"
      },
      "outputs": [],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35J6nYccF-ns"
      },
      "outputs": [],
      "source": [
        "print(f'(MOVIES, COLUMNS) -> {df.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iLYzakZF-ns"
      },
      "source": [
        "## TEST\n",
        "\n",
        "Use Selenium to scrape Box Office Mojo's top \\#100 for every year between 2002 and 2019.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JPbmUttF-ns"
      },
      "outputs": [],
      "source": [
        "url = 'https://www.boxofficemojo.com/intl/uk/yearly/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjnuUquSF-nt"
      },
      "outputs": [],
      "source": [
        "print(requests.get('https://www.nesta.org.uk/robots.txt').text)\n",
        "print('-----')\n",
        "print(requests.get('https://www.boxofficemojo.com/robots.txt').text)\n",
        "print('-----')\n",
        "print(requests.get('https://www.howtogeek.com/robots.txt').text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuI19PTaF-nt"
      },
      "outputs": [],
      "source": [
        "headers = {\n",
        "    'User-Agent': 'Kostas Stathoulopoulos bot',\n",
        "    'From': 'konstantinos.stathoulopoulos@nesta.org.uk'\n",
        "}\n",
        "request = requests.get('https://www.nesta.org.uk/', headers=headers)\n",
        "print(request.request.headers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qGKA0eHF-nu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ygqryk8NF-nZ",
        "sHtfX9gSF-nZ",
        "QGDOrb6mF-nb",
        "BiXvT4BUF-nm",
        "ip6xbD2oF-np",
        "rCWVrF3dF-nr",
        "_iLYzakZF-ns",
        "NecD7qklF-ns",
        "miyHNzhsF-nt",
        "QxSIZzvUF-nt"
      ],
      "name": "Web Scraping Tutorial - Very Useful.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python [conda env:py36]",
      "language": "python",
      "name": "conda-env-py36-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
